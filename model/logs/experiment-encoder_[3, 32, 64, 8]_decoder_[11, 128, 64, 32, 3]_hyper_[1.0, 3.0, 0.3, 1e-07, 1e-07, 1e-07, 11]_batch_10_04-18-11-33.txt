Starting encoder_[3, 32, 64, 8]_decoder_[11, 128, 64, 32, 3]_hyper_[1.0, 3.0, 0.3, 1e-07, 1e-07, 1e-07, 11]_batch_10_04-18-11-33 experiment
val_loss: 38.177
val_loss: 14.413
model saved.
val_loss: 14.615
val_loss: 11.866
model saved.
val_loss: 10.357
model saved.
val_loss: 9.371
model saved.
val_loss: 8.615
model saved.
val_loss: 7.812
model saved.
val_loss: 7.996
val_loss: 7.652
model saved.
val_loss: 7.553
model saved.
val_loss: 7.033
model saved.
val_loss: 7.166
val_loss: 6.907
model saved.
val_loss: 6.917
val_loss: 6.820
model saved.
val_loss: 6.631
model saved.
val_loss: 6.571
model saved.
val_loss: 6.146
model saved.
val_loss: 5.979
model saved.
val_loss: 5.862
model saved.
val_loss: 5.800
model saved.
val_loss: 5.629
model saved.
val_loss: 5.594
model saved.
val_loss: 5.340
model saved.
val_loss: 5.637
val_loss: 5.499
val_loss: 5.568
val_loss: 5.294
model saved.
val_loss: 5.354
val_loss: 5.353
val_loss: 4.980
model saved.
val_loss: 5.074
val_loss: 5.065
val_loss: 5.219
val_loss: 4.941
model saved.
val_loss: 4.946
val_loss: 5.222
val_loss: 4.904
model saved.
val_loss: 4.848
model saved.
val_loss: 5.126
val_loss: 5.344
val_loss: 5.169
val_loss: 4.755
model saved.
val_loss: 5.060
val_loss: 4.769
val_loss: 4.883
val_loss: 4.890
val_loss: 5.200
val_loss: 4.836
val_loss: 4.849
val_loss: 4.918
val_loss: 4.798
val_loss: 4.786
val_loss: 5.103
val_loss: 4.905
val_loss: 4.704
model saved.
val_loss: 4.917
val_loss: 4.829
val_loss: 4.952
val_loss: 4.810
val_loss: 4.917
val_loss: 4.730
val_loss: 4.786
val_loss: 4.660
model saved.
val_loss: 4.875
val_loss: 4.914
val_loss: 5.215
val_loss: 4.760
val_loss: 4.858
val_loss: 4.647
model saved.
val_loss: 5.036
val_loss: 4.831
val_loss: 4.864
val_loss: 4.642
model saved.
val_loss: 4.840
val_loss: 4.896
val_loss: 4.654
val_loss: 4.813
val_loss: 4.774
val_loss: 4.661
val_loss: 4.874
val_loss: 4.701
val_loss: 4.840
val_loss: 4.721
val_loss: 4.634
model saved.
val_loss: 4.665
val_loss: 4.659
val_loss: 4.728
val_loss: 4.827
val_loss: 4.615
model saved.
val_loss: 4.547
model saved.
val_loss: 4.737
val_loss: 4.550
val_loss: 4.828
val_loss: 4.573
val_loss: 4.666
val_loss: 4.722
val_loss: 4.837
val_loss: 4.618
val_loss: 4.614
val_loss: 4.828
val_loss: 4.705
val_loss: 4.611
val_loss: 4.816
val_loss: 4.624
val_loss: 4.569
val_loss: 4.771
val_loss: 4.815
val_loss: 4.513
model saved.
val_loss: 4.851
val_loss: 4.895
val_loss: 4.645
val_loss: 4.679
val_loss: 4.692
val_loss: 4.745
val_loss: 4.602
val_loss: 4.681
val_loss: 4.881
val_loss: 4.756
val_loss: 4.743
val_loss: 4.701
val_loss: 4.704
val_loss: 4.586
val_loss: 4.585
val_loss: 4.528
val_loss: 4.704
val_loss: 4.601
val_loss: 4.953
val_loss: 4.499
model saved.
val_loss: 4.912
val_loss: 4.623
val_loss: 4.705
val_loss: 4.622
val_loss: 4.637
val_loss: 4.850
val_loss: 4.707
val_loss: 4.643
val_loss: 4.531
val_loss: 4.549
val_loss: 4.892
val_loss: 4.540
val_loss: 4.710
val_loss: 4.647
val_loss: 4.844
val_loss: 4.534
val_loss: 4.896
val_loss: 4.556
val_loss: 4.602
val_loss: 4.881
Early stopping with 4.499 best score, the model did not improve after 20 iterations
